{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook selects data from 100 TF dataset based on the list25_path argument. This points at a csv file that should contain a column named TF (with a list of TFs to choose). Note: I have manually added GPBP1L1 to the original file, creating top_25_summary_GPBP1L1.csv (to have same dataset as Amber)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplefile_outdir = '/home/shush/profile/tfprofile/datasets/samplefiles/'\n",
    "list25_path = 'datasets/top_25_summary.csv'\n",
    "# list25_path = 'datasets/top_25_summary_GPBP1L1.csv'\n",
    "list25_df = pd.read_csv(list25_path, index_col=0)\n",
    "selected_tfs = list25_df['TFs'].values # make database from these\n",
    "\n",
    "# 100TF dataset location\n",
    "data_dir = '/mnt/31dac31c-c4e2-4704-97bd-0788af37c5eb/100_TF'\n",
    "summary_path = os.path.join(data_dir, 'summary.csv')\n",
    "summary_df = pd.read_csv(summary_path, index_col=0)\n",
    "labels = [l.split('TF-ChIP-seq_')[-1].split('-human')[0] for l in summary_df['label'].values]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding TF:  CTCF\n",
      "Adding TF:  MNT\n",
      "Adding TF:  UBTF\n",
      "Adding TF:  CREB1\n",
      "Adding TF:  ZFY\n",
      "Adding TF:  ARID5B\n",
      "Adding TF:  EGR1\n",
      "Adding TF:  ZNF574\n",
      "Adding TF:  HNF4A\n",
      "Adding TF:  ZNF776\n",
      "Adding TF:  ZBTB14\n",
      "Adding TF:  SP2\n",
      "Adding TF:  ELF1\n",
      "Adding TF:  FOXP4\n",
      "Adding TF:  ZNF709\n",
      "Adding TF:  ZNF547\n",
      "Adding TF:  ZNF331\n",
      "Adding TF:  TCF7L2\n",
      "Adding TF:  HIVEP1\n",
      "Adding TF:  ZNF274\n",
      "Adding TF:  ZNF800\n",
      "Adding TF:  LCORL\n",
      "Adding TF:  RXRA\n",
      "Adding TF:  USF1\n",
      "Adding TF:  DDIT3\n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for tf in selected_tfs:\n",
    "    if tf in labels:\n",
    "        print('Adding TF: ', tf)\n",
    "        i = labels.index(tf)\n",
    "        rows.append(summary_df.iloc[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = 'datasets/summary_25_links.csv'\n",
    "summary_25 = pd.DataFrame(rows)\n",
    "summary_25.to_csv(result_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in ['raw', 'sign', 'fold', 'bed']:\n",
    "    if folder == 'raw':\n",
    "        filetype = 'bam'\n",
    "    else:\n",
    "        filetype = folder\n",
    "    folder_dir = os.path.join(data_dir, folder)\n",
    "    filenames = [file.split('/')[-1] for file in summary_25[filetype].values]\n",
    "    if folder=='raw':\n",
    "        filenames = [file.replace('bam', 'bw') for file in filenames]\n",
    "    assert all([f in os.listdir(folder_dir) for f in filenames]), 'File not found'\n",
    "    labels = summary_25['label'].values\n",
    "    file_paths = [os.path.join(folder_dir, file) for file in filenames]\n",
    "\n",
    "    if filetype=='bed':\n",
    "        label = 'top25'\n",
    "        with open(os.path.join(samplefile_outdir, 'basset_sample_beds_{}.txt'.format(label)), 'w') as filehandle:\n",
    "            for i in range(len(labels)):\n",
    "                filehandle.write('{}\\t{}\\n'.format(labels[i], file_paths[i]))\n",
    "    else:\n",
    "        identifiers = [filename.split('.')[0] for filename in filenames]\n",
    "\n",
    "        first_line = '\\t'.join(['index', 'identifier', 'file', 'sum_stat', 'description'])\n",
    "        label = 'top25_'+filetype\n",
    "        with open(os.path.join(samplefile_outdir, 'basenji_sample_{}.txt'.format(label)), 'w') as filehandle:\n",
    "            filehandle.write('{}\\n'.format(first_line))\n",
    "            for i in range(len(file_paths)):\n",
    "                filehandle.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(i, identifiers[i],\n",
    "                                                               file_paths[i],\n",
    "                                                               'sum', labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0b3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
